---
layout: post
title: "Continuous Delivery for Mobile Development - Our learnings at Delta Air Lines"
type: post
author: Sanchit Bahal
excerpt: "This post chronicles the ThoughtWorks-Delta mobile app development team’s journey to continuous delivery, the challenges along the way and how they overcame them. "
title_tag_of_header: "Architecting for Continuous Delivery | GoCD Blog"
meta_description: "This post chronicles the ThoughtWorks-Delta mobile app development team’s journey to continuous delivery, the challenges along the way and how they overcame them."
meta_keywords: "trunk based development, feature toggles, feature flags, continuous integration, deployment pipeline"
summary_image: "/assets/images/blog/architecting-continuous-delivery/architecting-continuous-delivery-hero.jpg"
draft: true
---
<% content_for :banner do %>
<figure>
  <img src="/assets/images/blog/architecting-continuous-delivery/architecting-continuous-delivery-hero.jpg" alt="Architecting for Continuous Delivery"/>
</figure>
<% end %>

As a Principal Consultant for ThoughtWorks, I had the opportunity to work with Delta Air Lines to build their [consumer facing mobile application](https://www.thoughtworks.com/clients/delta). My role was to ensure that the application was technically sound and remove any roadblocks for the team. During my stint on the project, one of our challenges was to help the entire team adopt continuous delivery. We had a team of approximately 80 people distributed over two locations. This post chronicles our journey to continuous delivery, the challenges along the way, and how we overcame them. 

## How we overcame challenges on the road to Continuous Delivery

### 1. Replaced error-prone testing process with automation

The number one challenge with mobile app development is infrastructure. We had to run simulations of tests on different environments, the primary among them being a Mac OS (for the iOS app). At first, we did this manually over two days time, and obviously it was error prone: sometimes we forgot something or installed the wrong version. To resolve these issues, we created an image with a vanilla Mac OS environment that included all the software relevant to our tests. We called this our “**golden image**”.  At any time, if anything failed, or there was an issue, we just restored it to “the golden image”. We had a lot of snowflakes so having a golden image helped us eliminate all that.

### 2. Ended merge nightmares with feature toggles and trunk based development

Before I joined this project, the team were doing feature branches, which caused a lot of strain. This worsened when the team size grew and started expanding to a team distributed between two cities. Every time we merged a feature branch, it took a lot of effort and would halt everyone for a day or two before things went back to schedule.  

Making matters worse, we never ran continuous integration on these feature branches, we only had CI on our master. A branch where the code was getting pushed almost daily generally lived three to four months without continuous integration. People were doing their due diligence to make sure they'd merge master back into the feature branch to keep the code up to date, but that was never enough. We had eight feature teams in two locations; it was inevitable that people would cross paths. 

Another deeper problem caused by long-lived feature branches is that our team started becoming hesitant to do any re-factoring. When you know that the merge is going to be very difficult, people shy away from re-factoring even knowing that things are in bad shape. That meant that a huge amount of technical debt started accumulating.

After moving to  feature toggles and trunk-based development,  some of these challenges just went away. With every commit we are basically ensuring that we have a working product - which includes all our pipelines, all our unit tests, integration tests, smoke tests, etc. going green. So the level of confidence that the developers now have when pushing any piece of code is very high. 

### 3. Took advantage of a good continuous delivery tool 

#### Customization and the ability to orchestrate

Before we could start leveraging our CD tool, we had to make sure that we were able to automate and continuously integrate. A CD tool can only take you so far. That said, we found the pipelines in GoCD really powerful as a first class concept. Once we got the concepts of pipelines, stages, jobs, etc. we used GoCD to our advantage to build custom workflows and were able to define what CI/CD looked like for us. 

#### Traceability

Picking a tool that gives advanced traceability can save you a lot of time and agony. Recently, there was an issue that required us to make a <%= link_to "hotfix", '/posts/2017-06-20-hotfixes-rollback-rollforward.html' %> . Due to an error, the wrong git material was picked for the release pipeline. This resulted in the wrong artifact being produced and so there were random failures all over. What really helped us then, were the [GoCD labels](https://docs.gocd.org/current/configuration/build_labelling.html). This seemingly tiny piece of information on our pipeline helped us figure out what we were using the wrong branch! 

<img src="/assets/images/blog/delta-gocd/gocd-labels.png" alt="GoCD Labels"/>

It’s not uncommon for these types of incidents to happen in projects, and without a tool that offers traceability, it would take a lot of effort to troubleshoot. I couldn’t imagine the team being able to function if we removed GoCD from our processes.

### The impact of these changes 

> Honestly, the best thing after adopting continuous delivery is that we move much faster than before and with confidence.

The machine provisioning time reduced from two days to less than 30 minutes. The build waiting time and the time to get a build agent assigned to do the job, reduced from 6 hours to less than 10 seconds. What’s impactful is that less waiting means developers can focus without wasteful interruption. We have a big boost on team productivity. A positive change that we cannot really quantify was the effect on our culture! Our team was proactive about change. Continuous integration and automation became the new normal and we look at tech debt responsibly. 
  
After these improvements,  we wanted to go a bit further and find ways to improve our delivery process. We felt the need to have continuous monitoring or continuous feedback to keep understanding what needs to be fixed in our deployment cycle. This is the only place that I felt that tools like GoCD need to evolve. The idea was to get some reporting and actionable insights into our deployment cycle so we as a team can make changes as we go. Eventually, we built a custom analytics module suited for our application that we could draw insights from.

---

In my experience, continuous delivery is not an end or a goal - there’s no definite point in software development when you can say that now you are “doing CD”. But from where we started, the benefits we experienced using CD practices have been immeasurable. It can be a challenge in the beginning, but if you stick by it, it hugely improves not just the quality of code that gets delivered but the quality of the team as well. 